<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>11&nbsp; Error control, effect sizes and sample arrangement – Course notes on trial design</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./interpreting-trial-results/interpreting-trial-results.html" rel="next">
<link href="./running-a-trial/alternative-trial-design-processes.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-226bd0f977fa82dfae4534cac220d79a.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-be3c5a4880e563bd7b769321a328d6c1.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="11&nbsp; Error control, effect sizes and sample arrangement – Course notes on trial design">
<meta property="og:description" content="">
<meta property="og:image" content="https://trialdesign.jasoncollins.blog/img/errors.jpg">
<meta property="og:site_name" content="Course notes on trial design">
<meta name="twitter:title" content="11&nbsp; Error control, effect sizes and sample arrangement – Course notes on trial design">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://trialdesign.jasoncollins.blog/img/errors.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Course notes on trial design</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://www.jasoncollins.blog/"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.jasoncollins.blog/about/"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/jasonacollins/trialdesign" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./4-error-control-effect-sizes-and-sample-arrangement.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Error control, effect sizes and sample arrangement</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./experimental-foundations/experimental-foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Experimental foundations</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-foundations/why-experiment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Why experiment?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-foundations/the-experimental-approach-in-economics-and-psychology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The experimental approach in economics and psychology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-foundations/the-role-of-experiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The role of experiments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-foundations/randomised-trials.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Randomised trials</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-foundations/lab-versus-field.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Lab versus field</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-foundations/are-randomised-controlled-trials-ethical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Are randomised controlled trials ethical?</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./before-the-trial/before-the-trial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Before the trial</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./before-the-trial/organisational-buy-in.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Organisational buy-in</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./trial-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Trial basics</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./running-a-trial/running-a-trial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Running a trial</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./running-a-trial/level-of-outcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Level of outcome</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./running-a-trial/alternative-trial-design-processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Alternative trial design processes</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-error-control-effect-sizes-and-sample-arrangement.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Error control, effect sizes and sample arrangement</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./interpreting-trial-results/interpreting-trial-results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpreting trial results</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/navigating-the-literature.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Navigating the literature</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/the-replication-crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">The replication crisis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/replication-and-reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Replication and reproducibility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/publication-bias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Publication bias</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/p-hacking-and-the-garden-of-forking-paths.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">P-hacking and the garden of forking paths</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/pre-analysis-plans-and-preregistration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Pre-analysis plans and pre-registration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/type-m-and-type-s-errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Type S and M errors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/validity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Validity</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/generalisability-effect-sizes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Generalisability: effect sizes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/generalisability-context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Generalisability: context</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpreting-trial-results/heterogeneity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Heterogeneity</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#type-1-and-type-2-errors" id="toc-type-1-and-type-2-errors" class="nav-link active" data-scroll-target="#type-1-and-type-2-errors"><span class="header-section-number">11.1</span> Type 1 and Type 2 errors</a></li>
  <li><a href="#type-i-error-control" id="toc-type-i-error-control" class="nav-link" data-scroll-target="#type-i-error-control"><span class="header-section-number">11.2</span> Type I error control</a>
  <ul class="collapse">
  <li><a href="#multiple-comparisons" id="toc-multiple-comparisons" class="nav-link" data-scroll-target="#multiple-comparisons"><span class="header-section-number">11.2.1</span> Multiple comparisons</a></li>
  <li><a href="#replication-data-sets" id="toc-replication-data-sets" class="nav-link" data-scroll-target="#replication-data-sets"><span class="header-section-number">11.2.2</span> Replication data sets</a></li>
  </ul></li>
  <li><a href="#type-ii-error-control" id="toc-type-ii-error-control" class="nav-link" data-scroll-target="#type-ii-error-control"><span class="header-section-number">11.3</span> Type II error control</a>
  <ul class="collapse">
  <li><a href="#calculating-power" id="toc-calculating-power" class="nav-link" data-scroll-target="#calculating-power"><span class="header-section-number">11.3.1</span> Calculating power</a></li>
  <li><a href="#pre--and-post-experiment-power-analysis" id="toc-pre--and-post-experiment-power-analysis" class="nav-link" data-scroll-target="#pre--and-post-experiment-power-analysis"><span class="header-section-number">11.3.2</span> Pre- and post-experiment power analysis</a></li>
  <li><a href="#optional-reading" id="toc-optional-reading" class="nav-link" data-scroll-target="#optional-reading"><span class="header-section-number">11.3.3</span> Optional reading</a></li>
  </ul></li>
  <li><a href="#effect-sizes" id="toc-effect-sizes" class="nav-link" data-scroll-target="#effect-sizes"><span class="header-section-number">11.4</span> Effect sizes</a>
  <ul class="collapse">
  <li><a href="#cohens-d" id="toc-cohens-d" class="nav-link" data-scroll-target="#cohens-d"><span class="header-section-number">11.4.1</span> Cohen’s <em>d</em></a></li>
  <li><a href="#summarising-effect-sizes" id="toc-summarising-effect-sizes" class="nav-link" data-scroll-target="#summarising-effect-sizes"><span class="header-section-number">11.4.2</span> Summarising effect sizes</a></li>
  </ul></li>
  <li><a href="#randomisation-techniques" id="toc-randomisation-techniques" class="nav-link" data-scroll-target="#randomisation-techniques"><span class="header-section-number">11.5</span> Randomisation techniques</a>
  <ul class="collapse">
  <li><a href="#blocking" id="toc-blocking" class="nav-link" data-scroll-target="#blocking"><span class="header-section-number">11.5.1</span> Blocking</a></li>
  <li><a href="#within-subject-designs" id="toc-within-subject-designs" class="nav-link" data-scroll-target="#within-subject-designs"><span class="header-section-number">11.5.2</span> Within-subject designs</a></li>
  <li><a href="#cluster-randomisation" id="toc-cluster-randomisation" class="nav-link" data-scroll-target="#cluster-randomisation"><span class="header-section-number">11.5.3</span> Cluster randomisation</a></li>
  </ul></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"><span class="header-section-number">12</span> </a>
  <ul class="collapse">
  <li><a href="#module-2-summary" id="toc-module-2-summary" class="nav-link" data-scroll-target="#module-2-summary"><span class="header-section-number">12.1</span> Module 2 summary</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">12.2</span> References</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/jasonacollins/trialdesign/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Error control, effect sizes and sample arrangement</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In this chapter, I explore some particular elements of hypothesis testing. I will discuss how to reduce error, interpret effect size and arrange the random sample. I will close the chapter with a discussion of how pre-registration and pre-analysis plans can improve our practices.</p>
<section id="type-1-and-type-2-errors" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="type-1-and-type-2-errors"><span class="header-section-number">11.1</span> Type 1 and Type 2 errors</h2>
<p>Statistical tests are often thought of in terms of the errors they can generate.</p>
<p>The first error is where the test rejects a null hypothesis that is true. You find an effect where none exists. This is known as a <strong>Type I error</strong>, or false positive.</p>
<p>We set the rate at which Type I errors occur. The significance level <span class="math inline">\alpha</span> is the rate of Type I errors. If we use a significance level of 0.05, we have a 5% probability of rejecting the null hypothesis when it is true, generating a Type I error.</p>
<p>The second error is when we fail to reject a false null hypothesis. We do not find an effect where one exists. This is known as a <strong>Type II error</strong>, or false negative.</p>
<p>The Type II error rate is unknown, but can be calculated if we make a number of assumptions. We will examine this in the following pages. The type II error rate is denoted by <span class="math inline">\beta</span>.</p>
<p>The relationship between these errors and correct inference is shown in the following table.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Null hypothesis (<span class="math inline">H_0</span>) is true</th>
<th>Null hypothesis (<span class="math inline">H_1</span>) is false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Don’t reject</strong> <span class="math inline">H_0</span></td>
<td>True negative. Probability = <span class="math inline">1-\alpha</span></td>
<td>Type II error (false negative). Probability = <span class="math inline">\beta</span></td>
</tr>
<tr class="even">
<td><strong>Reject</strong> <span class="math inline">H_0</span></td>
<td>Type I error (false positive). Probability = <span class="math inline">\alpha</span></td>
<td>True positive. Probability = <span class="math inline">1-\beta</span></td>
</tr>
</tbody>
</table>
<p>The following diagrams provide another view on these errors.</p>
<p>As per our running example, suppose we are estimating two sample means for how many people submit their tax return on time. We want to know whether the difference between them represents a true effect of the intervention. Let us suppose that the null hypothesis is true and there is no effect.</p>
<p>As we have discussed, the estimate of the effect is with error. Our estimate may vary from the true value. That estimate will fall within a probability distribution of mean <span class="math inline">\mu</span> and standard deviation <span class="math inline">\frac{\sigma}{\sqrt{n}}</span>. The curve below represents that probability distribution.</p>
<p>When we set <span class="math inline">\alpha=0.05</span>, we are setting a critical value such that there is a 0.05 chance that the estimate will be above the critical value, despite the null hypothesis being true. The red shaded area is the probability of type I error.</p>
<p>[For this version of the diagram, only show the bell curve on the left. Remove the curve on the right and the shaded green area. Change “Any mean” to “Critical value”.]</p>
<p><a href="img/errors.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="img/errors.jpg" class="img-fluid"></a></p>
<p>Let us now assume there is an effect of our intervention. The alternative hypothesis is true.</p>
<p>Our estimate of this effect will again be with error, falling within a probability distribution of mean <span class="math inline">\mu</span> and standard deviation <span class="math inline">\frac{\sigma}{\sqrt{n}}</span>, but this time with <span class="math inline">\mu</span> representing a positive effect. This is represented by the curve on the right.</p>
<p>As you can see in the diagram, there is a probability that even if the effect is true, the measured value of the effect will fall below the critical value. You will fail to reject the null even though the alternative hypothesis is true. The green shaded area represents this probability of a Type II error.</p>
<p>[Tweaks to make to diagram: change “Any mean” to “Critical value”; delete “Null” and “Theoretical non-null value” with <span class="math inline">\bar{x}_1</span>]</p>
<p><a href="img/errors.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="img/errors.jpg" class="img-fluid"></a></p>
<p>Versions of diagram: 1. As in week 3.4 - normal distribution 2. As in week 3.5 - critical value 3. As here - version just null hypothesis curve 4. As here - version both curves 5. (for 4.3) Shifting H1 curve to the left or right - illustrate more/less chance of type II error if small/large effect size 6. (for 4.3) Larger sample size - reduce chance of type II error - bell curves getting taller and narrower, so green area shrinks 7. Trade-off between type 1 and 2 errors - changing significance level - slider??</p>
</section>
<section id="type-i-error-control" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="type-i-error-control"><span class="header-section-number">11.2</span> Type I error control</h2>
<p>We set the rate of Type 1 errors through the significance level. A standard significance level of <span class="math inline">\alpha=0.05</span> gives a 5% false positive rate if the null hypothesis is true.</p>
<p>There are many recent arguments that <span class="math inline">\alpha</span> should be smaller than 0.05, such as Benjamin et al’s (2018) argument that <span class="math inline">\alpha</span> should be set at 0.005. Many of these relate to the replication crisis that we will cover this later in this course. We simply want to generate less false positives.</p>
<section id="multiple-comparisons" class="level3" data-number="11.2.1">
<h3 data-number="11.2.1" class="anchored" data-anchor-id="multiple-comparisons"><span class="header-section-number">11.2.1</span> Multiple comparisons</h3>
<p>One scenario where there is a longer history of using a smaller alpha is where you are testing multiple hypotheses. This could arise because you have multiple treatment groups or because you are measuring many potential outcomes.</p>
<p>If you are testing many hypotheses, it becomes increasingly likely that at least one of them will meet the statistical threshold merely by chance. If you conduct 20 tests and all of null hypothesis for each test is true, you expect one false positive.</p>
<p>https://imgs.xkcd.com/comics/significant.png</p>
<p>A common correction applied to <span class="math inline">\alpha</span> in instances of multiple comparisons is the Bonferroni correction. If you are testing <em>m</em> hypotheses, set the significance level for each hypothesis at <span class="math inline">\frac{\alpha}{m}</span>. The Bonferroni correction is conservative in that it decreases the family-wise error rate - which is the probability of making one or more false discoveries - to below 0.05.</p>
<p>A Bonferroni type correction is typically applied where there is large-scale multiple testing. In genomic association studies, where they are testing of the order of a million genetic variants, they will normally set the significance level at 5x10<span class="math inline">^{-8}</span></p>
<p>A smaller significance level and associated higher critical value means, however, that we will get a higher rate of Type II errors. We will discuss this in the following pages.</p>
</section>
<section id="replication-data-sets" class="level3" data-number="11.2.2">
<h3 data-number="11.2.2" class="anchored" data-anchor-id="replication-data-sets"><span class="header-section-number">11.2.2</span> Replication data sets</h3>
<p>An alternative method of Type I error control is use of a replication sample, which is a subset of the data that is excluded from the initial analysis. If there are any significant results in the first analysis, testing for those hypotheses that were significant in the first is conducted on the replication sample.</p>
<p>This approach is common in machine learning applications, but is starting to become more common in statistical analysis. However, it is rarely used in experimental analysis.</p>
<p>We will cover the concept of replication more broadly in week 6.</p>
</section>
</section>
<section id="type-ii-error-control" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="type-ii-error-control"><span class="header-section-number">11.3</span> Type II error control</h2>
<p>The probability of a Type II error is <span class="math inline">\beta</span>, the probability that you will not reject the null hypothesis when it is false.</p>
<p>A related concept is power, which is the probability that you will <em>reject</em> the null hypothesis when it is false. Power is equal to 1 - <span class="math inline">\beta</span>.</p>
<p>Questions related to the Type II error rate for a trial are typically framed in terms of power. How can I design my trial so that it has enough power to reject the null hypothesis in circumstances where it is not true? Alternatively, how can I increase the probability that my trial will achieve statistical significance when the null hypothesis is not true?</p>
<section id="calculating-power" class="level3" data-number="11.3.1">
<h3 data-number="11.3.1" class="anchored" data-anchor-id="calculating-power"><span class="header-section-number">11.3.1</span> Calculating power</h3>
<p>Statistical power can be calculated with the following variables:</p>
<p><strong>The significance level</strong>: The stricter the significance level that you use in your experiment, the lower the power of the experiment. There is a trade-off between Type I and Type II errors. As you decrease the probability of false positives by using a stricter significance level, you also decrease the probability of true positives. You should not relax the significance level to achieve power, but should be aware of the consequences of making it more strict.</p>
<p><strong>The effect size</strong>: What is the magnitude of the effect of your intervention? The larger the effect size, the more power the experiment has to detect an effect and generate a statistically significant outcome.</p>
<p>Unfortunately, as you have not yet run the experiment, you do not know what the effect size is. If there are other studies with which parallels can be drawn, you can make an educated guess as to its likely size. You might generate your estimate through a literature review, pilot studies or other related experiments.</p>
<p>Estimates of the effect size should be conservative. As we will see later in this unit, the experimental literature is full of over-exaggerated effect sizes. An overestimate of the effect size will overestimate the power of the experiment.</p>
<p>You also need to understand the variability of the effect size (such as its standard deviation in the population of interest) to calculate power. A highly-variable effect will have a higher standard error in its measurement, so more probability of getting an extreme result that generates an error.</p>
<p>As a result, when an effect size estimate is made, it it typically made as a standardised effect size. This is the magnitude of the effect divided by the standard deviation. How many standard deviations is the effect?</p>
<p>You don’t have the ability to increase the effect size. However, variation in the effect size is affected by things such as measurement error. More precise measurement can increase power.</p>
<p><strong>The sample size</strong>: Power is a function of the sample size of the experiment. It is the factor over which you have the most control.</p>
<p>Increasing the sample size reduces the standard error of your estimated effect size. This means that, if the alternative hypothesis is true, you will have a greater probability of detecting an effect of any given size. This can be seen in the following diagram: a larger sample size results in lower standard error, which is reflected in a narrower probability distribution for your estimate.</p>
<p>[ADD GRAPHIC OF NORMAL DISTRIBUTION GETTING NARROWER]</p>
<p>Beyond increasing power, larger samples have other benefits such as reducing the extent to which we overestimate the effect size. We will discuss this more in coming material.</p>
<p>Power is calculated by asking, given the critical value implied by the chosen significance level, what effect size is required such that 80% of the probability distribution for the estimated effect size will be above the critical value.</p>
</section>
<section id="pre--and-post-experiment-power-analysis" class="level3" data-number="11.3.2">
<h3 data-number="11.3.2" class="anchored" data-anchor-id="pre--and-post-experiment-power-analysis"><span class="header-section-number">11.3.2</span> Pre- and post-experiment power analysis</h3>
<p>Power calculations should normally be done <strong>before</strong> an experiment. It is used to determine what sample size is required to obtain the requisite power. A common practice is obtaining a sample size sufficient to achieve 80% power, although there is little reason to limit yourself to that level of power if you can increase power at modest cost.</p>
<p>Power calculations are also often done after an experiment. You will see in the literature that post-experiment power calculations are regularly used to justify that the experiment had sufficient power, with the effect size found in the experiment the basis for the power calculation. This is poor practice, as a significant result in an underpowered experiment will tend to exaggerate the effect size. If you then use this exaggerated effect to calculate power, it gives the impression that the experiment was adequately powered. We will discuss this exaggeration of effect size later in the unit.</p>
<p>If a power calculation is done after the experiment, it should only be done using a well-grounded assumed effect size, not the effect size observed in the experiment.</p>
<p>An alternative use of post-experiment power calculations is to examine whether published experiments should be showing the proportion of significant results that they do. If a set of experiments has average power of 80%, only 80% of them should find a statistically significant effect. A higher proportion suggests publication bias (a topic later in the unit). The reading below examines a chapter of Daniel Kahneman’s <em>Thinking, Fast and Slow</em> using this tool.</p>
</section>
<section id="optional-reading" class="level3" data-number="11.3.3">
<h3 data-number="11.3.3" class="anchored" data-anchor-id="optional-reading"><span class="header-section-number">11.3.3</span> Optional reading</h3>
<p>Schimmack (2017) “Reconstruction of a Train Wreck: How Priming Research Went Off the Rails”, <em>Replicability-Index</em>, https://replicationindex.com/2017/02/02/reconstruction-of-a-train-wreck-how-priming-research-went-of-the-rails/ (Note Daniel Kahneman’s <a href="https://replicationindex.com/2017/02/02/reconstruction-of-a-train-wreck-how-priming-research-went-of-the-rails/comment-page-1/#comment-1454">response in the comments</a>.)</p>
</section>
</section>
<section id="effect-sizes" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="effect-sizes"><span class="header-section-number">11.4</span> Effect sizes</h2>
<p>Statistical significance is not the same as practical importance. A statistically significant result may not be large enough to matter in practice. You are interested not just in whether a treatment affects people, but also how much.</p>
<p>For example, which is the more interesting result? A statistically significant experimental treatment that could boost the financial wellbeing of all Australian by $2 (p=0.04). Or a non-significant experimental treatment that could boost the financial wellbeing of all Australians by $1000 (p=0.06)?</p>
<p>Effect sizes from experiments should be interpreted and reported with caution. While often reported as a point estimate, we can provide a confidence interval around the estimated effect size. The confidence interval for an effect size with a p-value marginally below 0.05 will have a confidence interval with a lower end only marginally above 0. As we will discuss later in this unit, effect sizes are often exaggerations of the true effect size.</p>
<section id="cohens-d" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1" class="anchored" data-anchor-id="cohens-d"><span class="header-section-number">11.4.1</span> Cohen’s <em>d</em></h3>
<p>One common way in which effect size’s are talked about is “Cohen’s <em>d</em>”. Cohen’s <em>d</em> is defined as the difference of two means divided by the standard deviation of the data. It is calculated as:</p>
<p><span class="math inline">d=\frac{\bar{x}_1-\bar{x}_0}{s}=\frac{\mu_1-\mu_0}{s}</span></p>
<p>where <em>s</em> is the pooled standard deviation of the data (you don’t have to know how to calculate that.)</p>
<p>Cohen’s <em>d</em> has the benefit of translating effect sizes in different experiments onto a common scale. You can speak of how many standard deviations an effect size is.</p>
<p>One legacy of Cohen’s that you will often encounter is that he also labelled different sizes of Cohen’s <em>d</em>. A Cohen’s <em>d</em> of 0.2 is a small effect, 0.5 is medium, and 0.8 is a large. When people are calculating power for an experiment, they will often think in terms of whether the effect is small, medium or large, and use the associated number. One way this can mislead, however, is that many effect sizes in the social sciences are far less than 0.2.</p>
</section>
<section id="summarising-effect-sizes" class="level3" data-number="11.4.2">
<h3 data-number="11.4.2" class="anchored" data-anchor-id="summarising-effect-sizes"><span class="header-section-number">11.4.2</span> Summarising effect sizes</h3>
<p>One place you often see transparent communication of effect sizes are in meta-analyses (summaries of the literature) or multi-lab replications. (More on these later in the unit.) Below is one example. (Note that the effect sizes are standardised as Cohen’s <em>d</em>.)</p>
<section id="the-jam-experiment" class="level4" data-number="11.4.2.1">
<h4 data-number="11.4.2.1" class="anchored" data-anchor-id="the-jam-experiment"><span class="header-section-number">11.4.2.1</span> The jam experiment</h4>
<p>On two Saturdays in a California supermarket, Mark Lepper and Sheena Iyengar set up tasting displays of either six or 24 jars of jam. Consumers could taste as many jams as they wished, and if they approached the tasting table they received a $1 discount coupon to buy the jam.</p>
<p>For attracting initial interest, the large display of 24 jams did a better job, with 60 per cent of people who passed the display stopping. Forty per cent of people stopped at the six jam display. But only three per cent of those who stopped at the 24 jam display purchased any of the jam, compared with almost 30 per cent who stopped at the six jam display.</p>
<p>This result has become the classical example of the “paradox of choice”. More choice can lead us to fail to make a choice.</p>
<p>Later, Benjamin Scheibehenne and friends surveyed the literature on the choice overload hypothesis. This chart is a a plot of the effect sizes across the literature. Of those that are significant - that is, those for which the 95% confidence interval does not contain zero - they have a large point estimate of effect size, yet a 95% confidence interval barely excluding zero.</p>
<p>Looking across these experiments, in some cases, choice increases purchases. In others it reduces them. Scheibehenne and friends determined that the mean effect size of changing the number of choices across the studies was effectively zero.</p>
<p><a href="img/scheibehenne.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="img/scheibehenne.jpg" class="img-fluid"></a></p>
</section>
</section>
</section>
<section id="randomisation-techniques" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="randomisation-techniques"><span class="header-section-number">11.5</span> Randomisation techniques</h2>
<p>As we discussed in week 2, randomisation provides indirect control of uncontrolled variables. It provides us with a way to infer that differences in outcomes are due to the treatments and not due to the individual characteristics of the experimental participants.</p>
<p>However, randomisation is not a panacea, nor is it always practical to undertake a pure randomisation. The below discusses some complications that can be involved in randomisation.</p>
<section id="blocking" class="level3" data-number="11.5.1">
<h3 data-number="11.5.1" class="anchored" data-anchor-id="blocking"><span class="header-section-number">11.5.1</span> Blocking</h3>
<p>Randomisation can occasionally lead to a large correlation between treatments and uncontrolled nuisance variables within a trial. For example, your control and intervention groups, by chance, may end up having people with higher incomes in one group than the other, or an unbalanced mix of sexes. If you are running only a small number of trials (often only one), this lack of balance can bias your results.</p>
<p>The following excerpt gives an example where two groups in a field trial became unbalanced.</p>
<blockquote class="blockquote">
<p>[I]n 2012, we came up with a seemingly costless simple intervention: Get people to sign a tax or insurance audit form before they reported critical information (versus after, the common business practice).</p>
<p>We ran studies showing that when people signed an honesty declaration before reporting information, they thought about how they were honest people, and were less likely to misreport compared to when they signed after they had filled out the form. While our original set of studies found that this intervention worked in the lab and in one field experiment, we no longer believe that signing before versus after is a simple costless fix. …</p>
<p>In an attempt to replicate and extend our original findings, three people on our team (Kristal, Whillans and Bazerman) found no evidence for the observed effects across five studies with 4,559 participants. We brought the original team together and reran an identical lab experiment from the original paper (Experiment 1). The only thing we changed was the sample size: we had 20 times more participants per condition. And we found no difference in the amount of cheating between signing at the top of the form and signing at the bottom.</p>
<p>In light of these findings, we reanalyzed the field study in the original paper and became concerned with a failure of random assignment (such that the number of miles driven before the intervention was delivered was significantly different between the two groups). What we originally thought to be a reporting difference (between customers who signed at the top versus bottom of the form) now seems more likely to be a difference in actual driving behavior—not the honest or dishonest reporting of it.</p>
<p>Kristal et al (2020)</p>
</blockquote>
<p>There are experimental designs that can reduce the effect of unbalanced groups. These work by holding a set of variables constant within a subset of trials (“a block”). These variables are often called blocking variables.</p>
<p>For example, suppose we are going to test discrimination in hiring by sending CVs in response to job ads. We believe that large and small firms will respond differently. We can split the firms into two blocks, small and large, and then randomise within each of those blocks. This will balance the small and large firms across the control and intervention groups and ensure we don’t get an unbalanced experiment on that dimension.</p>
</section>
<section id="within-subject-designs" class="level3" data-number="11.5.2">
<h3 data-number="11.5.2" class="anchored" data-anchor-id="within-subject-designs"><span class="header-section-number">11.5.2</span> Within-subject designs</h3>
<p>Most of the experiments we have discussed involve what is called a “between-subject” design. The treatment and control groups comprise different subjects, with comparisons made between those subjects.</p>
<p>An alternative design is within-subject design, whereby experimental subjects make decisions in all treatments.</p>
<p>Suppose we are working on increasing on-time credit card payments by sending a reminder. We might run the trial over two periods, sending a reminder to half the participants for the first payment period, then a reminder to the other half in the second period. The control and treatment groups across the two periods are balanced as they contain the same people. This within-subjects design is called a crossover study, as participants cross over from one group to the other.</p>
<p>Under a within-subject design, each subject is effectively their own control, meaning that we do not need to worry about the different characteristics of decision makers. Apart from avoiding unbalanced treatment and control groups, this means that there is usually less variation in treatment effects, increasing the power of the experiment.</p>
<p>A major disadvantage of a within-subject design is that there may be “order effects”. The intervention in one period may flow into another period. There may be effects such as fatigue. The reverse order that participants receive the treatment in a “crossover” study, such as the example above, can be used to attempt to account for these order effects, although it complicates the analysis.</p>
<p>Within-subject designs tend to be used where we have a limited number of experimental participants or are looking for efficiencies in the conduct of the experiment, as the design can increase power with fewer participants relative to a between-subjects design. You might also use it where you are interested in the longitudinal aspect of the interventions.</p>
</section>
<section id="cluster-randomisation" class="level3" data-number="11.5.3">
<h3 data-number="11.5.3" class="anchored" data-anchor-id="cluster-randomisation"><span class="header-section-number">11.5.3</span> Cluster randomisation</h3>
<p>Sometimes it is not practicable to randomise experimental subjects individually. For example, suppose you are implementing a trial to improve on-time tax return submissions by phoning taxpayers. You want to test what scripts and tools for call centre staff are most effective in increasing on-time submission. Training in the tools are provided at staff briefings at the beginning of each shift, making it impracticable to randomise across call centre staff within the centre.</p>
<p>A common approach to deal with this problem is <em>cluster randomisation</em>. In cluster randomisation, groups of subjects are randomised. If you have 20 call centres, randomise those 20 into the treatment and control.</p>
<p>Cluster randomisation is also used to control for contamination across individuals, as a change in behaviour in one might change the behaviour of others. In our example above, even if it were possible to train staff separately with different treatments, they may become aware of other approaches of staff in their centre and change their behaviour as a result. If that is a concern, cluster randomisation might address this.</p>
<p>Cluster randomisation has costs. It introduces greater complexity into the analysis, including introducing potential intracluster correlation that should be accounted for. Cluster randomisation also reduces power by effectively reducing the sample size.</p>
</section>
</section>
<section id="section" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> </h1>
<section id="module-2-summary" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="module-2-summary"><span class="header-section-number">12.1</span> Module 2 summary</h2>
<p>In this module, we have examined the process of conducting a randomised controlled trial, how to test hypotheses, and the types of errors that can be generated.</p>
<p>As a warm up for the next module, watch this interview of Professor Dorothy Bishop by Sabine Hossenfelder.</p>
<p>https://youtu.be/v778svukrtU</p>
</section>
<section id="references" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="references"><span class="header-section-number">12.2</span> References</h2>
<p>Benjamin et al (2018) “Redefine statistical significance”, <em>Nature Human Behaviour</em>, 2, 6-10, https://doi.org/10.1038/s41562-017-0189-z</p>
<p>Iyengar and Lepper (2000) “When choice is demotivating: Can one desire too much of a good thing?”, <em>Journal of Personality and Social Psychology</em>, 79(6), 995–1006, https://doi.org/10.1037/0022-3514.79.6.995</p>
<p>Kristal et al (2020) “When We’re Wrong, It’s Our Responsibility as Scientists to Say So”, <em>Scientific American</em>, https://blogs.scientificamerican.com/observations/when-were-wrong-its-our-responsibility-as-scientists-to-say-so/</p>
<p>List, Sadoff and Magner (2010) “So you want to run an experiment, now what?Some simple rules of thumb for optimal experimental design”, <em>Experimental Economics</em>, https://doi.org/10.1007/s10683-011-9275-7</p>
<p>Scheibehenne, Greifeneder and Todd (2010) “Can There Ever Be Too Many Options? A Meta-Analytic Review of Choice Overload”, <em>Journal of Consumer Research</em>, 37(3), 409–425, https://doi.org/10.1086/651235</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/trialdesign\.jasoncollins\.blog");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./running-a-trial/alternative-trial-design-processes.html" class="pagination-link" aria-label="Alternative trial design processes">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Alternative trial design processes</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./interpreting-trial-results/interpreting-trial-results.html" class="pagination-link" aria-label="Interpreting trial results">
        <span class="nav-page-text">Interpreting trial results</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://creativecommons.org/licenses/by/4.0/">
<p>Copyright: CC-BY</p>
</a>
  </li>  
</ul>
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/jasonacollins/trialdesign/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>