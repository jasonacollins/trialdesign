<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<title>14.2 Publication bias</title>
<meta name="identifier" content="gc8accd00dce1df05cbbf1b3c1a324d74"/>
<meta name="editing_roles" content="teachers"/>
<meta name="workflow_state" content="active"/>
</head>
<body>
<p><img id="4158537" src="$IMS-CC-FILEBASE$/Updated%20banners/23717_Trial_Design_Banner-24.png" alt="23717_Trial_Design_Banner-24.png" loading="lazy"></p>
<p>In 2011, the Journal of Personality and Social Psychology (a big, flagship journal) published a paper by Daryl Bem entitled "Feeling the Future: Experimental Evidence of Anomalous Retroactive Influences on Cognition and Affect."</p>
<p>In the paper, Bem described nine experiments. In the first experiment, participants were shown pictures of two curtains side-by-side on a screen. One had a picture behind it, the other a blank wall. The participants were asked to click on the curtain they felt had the picture behind it. They were then shown if they had selected the correct curtain.</p>
<p>Some of the pictures shown to the participants were "erotic". Where there was an erotic picture, participants selected the pictures more often than expected by chance: 53.1% of the time. For non-erotic pictures, the probability of success did not vary significantly from chance. The p-value for selecting the erotic pictures was 0.01, a significant result.</p>
<p>Would Bem's research have been published in a top psychology journal without a statistically significant result? Would the journal waste resources publishing a paper suggesting people do not have ESP?</p>
<p>This point is the essence of publication bias. Publication bias occurs when the outcome of an experiment influences whether it is published or not.</p>
<p>Studies that find significant effects are more likely to be published. This incentivises those conducting experiments only to write up their positive results. Studies that do not generate statistically significant results end up in the file drawer. Ultimately, the published literature ceases to be a representative sample of the evidence. Instead, it is biased.</p>
<h2>Analysis to identify publication bias</h2>
<p>While it is easy to see the incentives that might generate publication bias, measuring it is more difficult and sometimes controversial.</p>
<p>One common way is using a funnel plot, which is used to analyse for publication bias across a literature. The effect sizes of all experiments examining a particular intervention are plotted against the precision of the studies. Precision is usually proxied by study size or the standard error.</p>
<div class="content-box">
<div class="grid-row">
<div class="col-xs-12 col-md-6">
<div class="styleguide-section__grid-demo-element">
<div style="background-color: #efe5f9; padding: 15px 30px; min-height: 200px;">
<p>A literature in which all experimental results are published should see a spread of results around the effect size, with smaller or less precise studies having more variation around that point. This results in a funnel shape of results, as in the first diagram.</p>
<p><img src="$IMS-CC-FILEBASE$/Funnel%201-1.png" alt="Funnel 1" width="500" height="321" data-api-endpoint="https://canvas.uts.edu.au/api/v1/courses/25795/files/6396947" data-api-returntype="File" loading="lazy"></p>
</div>
</div>
</div>
<div class="col-xs-12 col-md-6">
<div class="styleguide-section__grid-demo-element">
<div style="background-color: #f7e5f9; padding: 15px 30px; min-height: 200px;">
<p>Where there is publication bias, there is often an asymmetry in that the results on one side of the funnel plot (typically the small sample studies that delivered results in the unintended direction) are missing.</p>
<p><img src="$IMS-CC-FILEBASE$/Funnel%202-1.png" alt="Funnel 2" width="500" height="321" data-api-endpoint="https://canvas.uts.edu.au/api/v1/courses/25795/files/6396930" data-api-returntype="File" loading="lazy"></p>
</div>
</div>
</div>
</div>
</div>
<p>Asymmetric funnel plots are not definitive of publication bias and rest on several assumptions, such as a lack of a systematic link between the size of the effect and the size of the study (which there may be if people use a larger sample because they believe the effect is small).</p>
<h3>Remedying publication bias</h3>
<p>A primary method proposed for reducing publication bias is the use of pre-registration. This provides a basis for understanding the full scope of the studies undertaken.</p>
<p>However, this is not a complete remedy as many pre-registered studies are not published, and their results are unavailable. That prevents us from obtaining a complete view of the experiments conducted.</p>
<div style="background-color: #f5f5f5; padding: 15px 30px; margin-bottom: 20px; margin-top: 20px;">
<p><strong>References</strong></p>
<p><i class="icon-link icon-solid" style="color: #8826ab;"></i><span>Bem (2011) "Feeling the future: Experimental evidence for anomalous retroactive influences on cognition and affect",&nbsp;</span><em>Journal of Personality and Social Psychology</em><span>, 100(3), 407â€“425,&nbsp;</span><a class="external" href="https://doi.org/10.1037/a0021524" target="_blank"><span>https://doi.org/10.1037/a0021524</span></a></p>
</div>
</body>
</html>