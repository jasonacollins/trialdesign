<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<title>15. Validity</title>
<meta name="identifier" content="gee78077d55534c3712084e0fcd3a5901"/>
<meta name="editing_roles" content="teachers"/>
<meta name="workflow_state" content="active"/>
</head>
<body>
<p><img id="4158473" src="$IMS-CC-FILEBASE$/Updated%20banners/23717_Trial_Design_Banner-14.png" alt="23717_Trial_Design_Banner-14.png" data-api-endpoint="https://canvas.uts.edu.au/api/v1/courses/25795/files/4158473" data-api-returntype="File" loading="lazy"></p>
<p>Validity is the extent to which the results of an experiment support a more general conclusion.</p>
<p>There are many forms of validity. Here we briefly define four (Salganik, 2018).</p>
<div class="content-box">
<div class="grid-row">
<div class="col-xs-12 col-md-4" style="text-align: center;">
<div class="styleguide-section__grid-demo-element">
<div style="background-color: #f7e5f9; padding: 15px 30px; min-height: 230px;">
<p><strong>Statistical conclusion validity</strong></p>
<p>is the extent to which the experimental statistical analysis was done directly. For example, did the experimenter calculate the p-values correctly?</p>
</div>
</div>
</div>
<div class="col-xs-12 col-md-4" style="text-align: center;">
<div class="styleguide-section__grid-demo-element">
<div style="background-color: #f8eafa; padding: 15px 30px; min-height: 230px;">
<p><strong>Construct validity</strong></p>
<p>concerns whether the data matches the theoretical constructs. If you believe that a social norm triggers someone to pay their tax on time, does your treatment manipulate social norms while holding other constructs (such as prompts) constant?</p>
</div>
</div>
</div>
<div class="col-xs-12 col-md-4">
<div class="styleguide-section__grid-demo-element">
<div style="background-color: #faeffb; padding: 15px 30px; min-height: 230px;">
<p style="text-align: center;"><strong>External validity</strong></p>
<p style="text-align: center;">is the extent that experimental findings can be generalised to the population from which the participants in the experiment were drawn. Field experiments tend to provide higher external validity than those constrained to the lab.</p>
</div>
</div>
</div>
</div>
</div>
<div style="background-color: #fbf4fc; padding: 15px 30px; min-height: 170px;">
<p style="text-align: center;"><strong>Internal validity</strong></p>
<p style="text-align: center;">is the extent to which the experimental treatment is actually responsible for the change in the value of the dependent variable. You are able to link cause and effect while controlling for the effect of outside variables (usually by randomisation). Internal validity also concerns whether the experimental procedures were performed correctly. Internal validity tends to be higher in the lab, although the failure of many lab experiments to replicate indicates a problem of low validity.</p>
</div>
<h2>The validity of lab and field experiments</h2>
<p>A core driver of whether a lab or field experiment is more appropriate is whether internal or external validity are more important.</p>
<p>In their <a href="https://voxeu.org/article/generalisability-experimental-results-economics" target="_blank">2014 article</a>, John List and Omar Al-Ubaydliin provide their perspective on trade-offs. They look at the <a class="inline_disabled" href="https://en.wikipedia.org/wiki/Dictator_game#Variants" target="_blank">Trust game</a>, and they describe a related field experiment.</p>
<p>The article provides an example where Bob and Susan are engaging in a simple trade of a mug via post. If Bob mails a check to Susan, can Bob can trust Susan to send the mug?</p>
<p>List and Al-Ubaydliin suggest looking at the Trust Game to understand whether Bob should trust Susan. The Trust Game has been covered in the previous unit 23715 Game Theory and Strategic Decision Making. You can review those pages to remind yourselves of how the game works. A common result of the game in the lab is that strangers trust each other. If trusted, strangers altruistically show themselves to be trustworthy.</p>
<p>But should these experimental results provide comfort to Bob? List and Al-Ubaydliin describe a related field experiment. The example relates to a field experiment that reflects the trust game, except it involves professional traders trading sports memorabilia. The results depicted a stark image of anonymous trade when property rights were not present, with little evidence of altruism. The authors ask: would Bob and Susan engage in their trade if they were familiar with this literature?</p>
<p>To learn in detail about List and Al-Ubaydliin's study, access and read <a href="https://voxeu.org/article/generalisability-experimental-results-economics" target="_blank">their article</a>.</p>
<h3><span style="font-size: 18pt;">The validity of randomised controlled trials</span></h3>
<p>Much of this unit has focussed on how we can use randomised controlled trials to obtain accurate measures of treatment effects, as opposed to delving into how the results could be used. This is effectively a focus on internal validity.</p>
<div class="content-box">
<div class="grid-row">
<div class="col-xs-12 col-md-9">
<div class="styleguide-section__grid-demo-element">
<p>This unit's focus is matched in much of the literature about randomised controlled trials. External validity is often an afterthought. And in an article arguing <strong>against</strong> placing randomised controlled trials on a pedestal, Angus Deaton and Nancy Cartwright agree that this can have value:</p>
<blockquote style="background: #f9f9f9; margin: 25px 0px; padding: 15px 25px 15px 25px; border-left: 6px solid #ab2567;">
<p>Suppose a trial has (probabilistically) established a result in a specific setting. If ‘the same’ result holds elsewhere, it is said to have external validity. External validity may refer just to the replication of the causal connection or go further and require replication of the magnitude of the averige treattmenr effect (ATE). Either way, the result holds—everywhere, or widely, or in some specific elsewhere—or it does not.<br><br>This binary concept of external validity is often unhelpful because it asks the results of an randomized control trial (RCT) to satisfy a condition that is neither necessary nor sufficient for trials to be useful, and so both overstates and understates their value. It directs us toward simple extrapolation—whether the same result holds elsewhere—or simple generalization—it holds universally or at least widely—and away from more complex but equally useful applications of the results. The failure of external validity interpreted as simple generalization or extrapolation says little about the value of the results of the trial.</p>
</blockquote>
</div>
</div>
<div class="col-xs-12 col-md-3">
<div class="styleguide-section__grid-demo-element">
<p>But this paragraph starts to shape the critique:</p>
<blockquote style="background: #f9f9f9; margin: 25px 0px; padding: 15px 25px 15px 25px; border-left: 6px solid #ab2567;">
<p>Establishing causality does nothing in and of itself to guarantee that the causal relation will hold in some new case, let alone in general. Nor does the ability of an ideal RCT to eliminate bias from selection or from omitted variables mean that the resulting ATE from the trial sample will apply anywhere else.</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="content-box pad-box-mini" style="background-color: #f5f5f5; padding: 20px;">
<p><strong>Activity</strong></p>
<p>Please answer the following question in no more than 100 words.</p>
<p>In what circumstances might external validity be of limited importance?</p>
<p><iframe style="width: 100%; height: 600px;" src="$CANVAS_COURSE_REFERENCE$/external_tools/retrieve?display=borderless&amp;url=https%3A%2F%2Fdiscussions.atomicjoltappsau.com%2Flti_launches%2FSbd3cDebmjXKbboGEde5D4V7" width="100%" height="198px" loading="lazy" allowfullscreen="allowfullscreen" webkitallowfullscreen="webkitallowfullscreen" mozallowfullscreen="mozallowfullscreen" allow="geolocation *; microphone *; camera *; midi *; encrypted-media *; autoplay *"></iframe></p>
</div>
<p>&nbsp;</p>
<div style="background-color: #f5f5f5; padding: 15px 30px;">
<p><strong>Optional reading</strong></p>
<p>Deaton and Cartwright (2018) "Understanding and misunderstanding randomized controlled trials", <em>Social Science and Medicine</em>, 210, 2-21, <a href="https://doi.org/10.1016/j.socscimed.2017.12.005">https://doi.org/10.1016/j.socscimed.2017.12.005</a></p>
<p><strong>References</strong></p>
<p>Levitt and List (2007) "What Do Laboratory ExperimentsMeasuring Social Preferences Reveal About the Real World?", <em>Journal of Economic Perspectives</em>, 21(2), 153-174, <a href="https://doi.org/10.1257/jep.21.2.153">https://doi.org/10.1257/jep.21.2.153</a></p>
<p>List and Al_Ubaydli (2014) "The generalisability of experimental results in economics", <em>VOXEU</em>, <a href="https://voxeu.org/article/generalisability-experimental-results-economics">https://voxeu.org/article/generalisability-experimental-results-economics</a></p>
<p>Salganik (2018) <em>Bit by Bit: Social Research in the Digital Age,</em> Princeton University Press, Princeton<em></em></p>
</div>
</body>
</html>